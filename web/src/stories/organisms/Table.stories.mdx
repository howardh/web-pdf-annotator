import { Meta, Story, Canvas } from '@storybook/addon-docs/blocks';
import { Table } from 'organisms/Table.js'
import { toRelativeDateString } from 'Utils.js';
import { DocumentTable } from 'Documents.js'

<Meta title="Organisms/Table"/>

export const entities = {"5": {"id": 5, "user_id": 1, "url": "https://arxiv.org/pdf/2007.08794.pdf", "title": "Discovering Reinforcement Learning Algorithms", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": null, "last_accessed_at": null, "tag_names": []}, "6": {"id": 6, "user_id": 1, "url": "https://arxiv.org/pdf/2010.01069.pdf", "title": "A Deeper Look at Discounting Mismatch in Actor-Critic Algorithms", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": null, "last_accessed_at": null, "tag_names": []}, "7": {"id": 7, "user_id": 1, "url": "https://arxiv.org/pdf/2010.13685.pdf", "title": "Forethought and Hindsight in Credit Assignment", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": null, "last_accessed_at": null, "tag_names": []}, "12": {"id": 12, "user_id": 1, "url": "https://proceedings.neurips.cc/paper/2020/file/216f44e2d28d4e175a194492bde9148f-Paper.pdf", "title": "Reinforcement Learning for Control with Multiple Frequencies", "author": "Part of Advances in Neural Information Processing Systems 33  pre-proceedings (NeurIPS 2020)", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-12-06T23:08:18.015355+00:00", "last_accessed_at": null, "tag_names": []}, "15": {"id": 15, "user_id": 1, "url": "https://www.frontiersin.org/articles/10.3389/fncir.2018.00121/pdf", "title": "A Framework for Intelligence and Cortical Function Based on Grid Cells in the Neocortex", "author": "Jeff Hawkins, Marcus Lewis, Mirko Klukas, Scott Purdy and Subutai Ahmad", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-12-26T19:16:09.050137+00:00", "last_accessed_at": null, "tag_names": ["neuroscience"]}, "13": {"id": 13, "user_id": 1, "url": "https://proceedings.neurips.cc/paper/2020/file/fe73f687e5bc5280214e0486b273a5f9-Paper.pdf", "title": "Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning", "author": "Part of Advances in Neural Information Processing Systems 33  pre-proceedings (NeurIPS 2020)", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-12-08T00:39:06.680719+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "19": {"id": 19, "user_id": 1, "url": "https://arxiv.org/pdf/1812.02868.pdf", "title": "Measuring and Characterizing Generalization in Deep Reinforcement Learning", "author": "Sam Witty, Jun Ki Lee, Emma Tosch, Akanksha Atrey, Michael Littman, David Jensen", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-02-17T01:54:09.904193+00:00", "last_accessed_at": null, "tag_names": []}, "14": {"id": 14, "user_id": 1, "url": "https://arxiv.org/pdf/1810.00123.pdf", "title": "Generalization and Regularization in DQN", "author": "Jesse Farebrother, Marlos C. Machado, Michael Bowling", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-12-08T13:26:20.110713+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "33": {"id": 33, "user_id": 1, "url": "https://arxiv.org/pdf/1911.04448.pdf", "title": "Real-Time Reinforcement Learning", "author": "Simon Ramstedt, Christopher Pal", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-04-23T19:29:11.559849+00:00", "last_accessed_at": null, "tag_names": []}, "1": {"id": 1, "user_id": 1, "url": "http://proceedings.mlr.press/v89/song19b/song19b.pdf", "title": "A General Framework for Multi-Fidelity Bayesian Optimization with Gaussian Processes", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-11-02T18:16:40.959333+00:00", "last_accessed_at": null, "tag_names": ["multifidelity"]}, "22": {"id": 22, "user_id": 1, "url": "https://arxiv.org/pdf/2102.12611.pdf", "title": "Improved Regret Bound and Experience Replay in Regularized Policy Iteration", "author": "Nevena Lazic, Dong Yin, Yasin Abbasi-Yadkori, Csaba Szepesvari", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-02T16:14:13.291349+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "2": {"id": 2, "user_id": 1, "url": "https://arxiv.org/pdf/2007.03117.pdf", "title": "Multi-Fidelity Bayesian Optimization via Deep Neural Networks", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-11-02T18:16:41.534856+00:00", "last_accessed_at": null, "tag_names": ["multifidelity"]}, "10": {"id": 10, "user_id": 1, "url": "https://www.cs.mcgill.ca/~prakash/Pubs/siamFP11.pdf", "title": "BISIMULATION METRICS FOR CONTINUOUS MARKOV DECISION PROCESSES", "author": "NORM FERNS, PRAKASH PANANGADEN, AND DOINA PRECUP", "bibtex": null, "read": null, "note_id": 55, "deleted_at": null, "last_modified_at": "2020-11-26T09:07:33.194464+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "9": {"id": 9, "user_id": 1, "url": "https://arxiv.org/pdf/2010.11151.pdf", "title": "Logistic $Q$-Learning", "author": "Joan Bas-Serrano, Sebastian Curi, Andreas Krause, Gergely Neu", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-11-04T19:02:57.408638+00:00", "last_accessed_at": null, "tag_names": []}, "11": {"id": 11, "user_id": 1, "url": "https://arxiv.org/pdf/2012.01399v1.pdf", "title": "Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER", "author": "Markus Holzleitner, Lukas Gruber, Jos\u00e9 Arjona-Medina, Johannes Brandstetter, Sepp Hochreiter", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2020-12-04T17:37:27.767222+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "4": {"id": 4, "user_id": 1, "url": "https://arxiv.org/pdf/1802.09081.pdf", "title": "Temporal difference models: Model-free deep rl for model-based control", "author": null, "bibtex": null, "read": false, "note_id": null, "deleted_at": null, "last_modified_at": "2020-11-04T21:45:08.631336+00:00", "last_accessed_at": null, "tag_names": ["model-based-rl"]}, "23": {"id": 23, "user_id": 1, "url": "https://arxiv.org/pdf/2103.00107.pdf", "title": "Revisiting Peng's Q($\u03bb$) for Modern Reinforcement Learning", "author": "Tadashi Kozuno, Yunhao Tang, Mark Rowland, R\u00e9mi Munos, Steven Kapturowski, Will Dabney, Michal Valko, David Abel", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-06T17:53:32.769218+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "21": {"id": 21, "user_id": 1, "url": "https://ojs.aaai.org/index.php/AAAI/article/view/12079/11938", "title": "Finite Sample Analyses for TD(0) with Function Approximation", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-02T16:03:06.316320+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "28": {"id": 28, "user_id": 1, "url": "https://arxiv.org/pdf/1809.02104.pdf", "title": "Are adversarial examples inevitable?", "author": "Ali Shafahi, W. Ronny Huang, Christoph Studer, Soheil Feizi, Tom Goldstein", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-23T10:17:03.582567+00:00", "last_accessed_at": null, "tag_names": []}, "20": {"id": 20, "user_id": 1, "url": "https://arxiv.org/pdf/1710.07283.pdf", "title": "Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning", "author": "Stefan Depeweg, Jos\u00e9 Miguel Hern\u00e1ndez-Lobato, Finale Doshi-Velez, Steffen Udluft", "bibtex": null, "read": null, "note_id": 64, "deleted_at": null, "last_modified_at": "2021-03-02T16:03:17.185389+00:00", "last_accessed_at": null, "tag_names": ["uncertainty"]}, "17": {"id": 17, "user_id": 1, "url": "https://www.eecs.qmul.ac.uk/~simond/pub/2019/BenetosDixonDuanEwert-IEEE-SPM-2019.pdf", "title": "Automatic music transcription: An overview", "author": null, "bibtex": null, "read": true, "note_id": 63, "deleted_at": null, "last_modified_at": "2021-01-14T11:52:18.193805+00:00", "last_accessed_at": null, "tag_names": ["music"]}, "3": {"id": 3, "user_id": 1, "url": "https://arxiv.org/pdf/1409.0473.pdf", "title": "NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING  TO ALIGN AND TRANSLATE", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": null, "last_accessed_at": null, "tag_names": ["language-models"]}, "24": {"id": 24, "user_id": 1, "url": "https://proceedings.neurips.cc/paper/2011/file/a8e864d04c95572d1aece099af852d0a-Paper.pdf", "title": null, "author": null, "bibtex": null, "read": null, "note_id": 65, "deleted_at": null, "last_modified_at": "2021-03-12T21:25:46.711333+00:00", "last_accessed_at": null, "tag_names": ["gaussian-process"]}, "18": {"id": 18, "user_id": 1, "url": "https://www.ee.columbia.edu/~dpwe/e6820/papers/SmarB03-nmf.pdf", "title": "Non-Negative Matrix Factorization for Polyphonic Music Transcription", "author": null, "bibtex": null, "read": null, "note_id": 68, "deleted_at": null, "last_modified_at": "2021-03-25T10:48:03.993538+00:00", "last_accessed_at": null, "tag_names": ["music"]}, "16": {"id": 16, "user_id": 1, "url": "https://arxiv.org/pdf/1801.01290.pdf", "title": "Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor", "author": "Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine", "bibtex": null, "read": null, "note_id": 60, "deleted_at": null, "last_modified_at": "2021-07-27T20:02:50.187466+00:00", "last_accessed_at": null, "tag_names": []}, "25": {"id": 25, "user_id": 1, "url": "https://publications.aston.ac.uk/id/eprint/1219/1/Advances_in_Neural_Information_Processing_Systems.pdf", "title": null, "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-14T01:41:14.957171+00:00", "last_accessed_at": null, "tag_names": ["gaussian-process"]}, "32": {"id": 32, "user_id": 1, "url": "https://people.eecs.berkeley.edu/~pabbeel/cs287-fa09/readings/KakadeLangford-icml2002.pdf", "title": "Approximately Optimal Approximate Reinforcement Learning", "author": " Sham Kakade, John Langford", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-31T07:46:52.812494+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "26": {"id": 26, "user_id": 1, "url": "https://dspace.mit.edu/bitstream/handle/1721.1/8599/49315318-MIT.pdf", "title": null, "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-03-16T05:17:18.118031+00:00", "last_accessed_at": null, "tag_names": []}, "29": {"id": 29, "user_id": 1, "url": "https://arxiv.org/pdf/1611.01224.pdf", "title": "Sample Efficient Actor-Critic with Experience Replay", "author": "Ziyu Wang, Victor Bapst, Nicolas Heess, Volodymyr Mnih, Remi Munos, Koray Kavukcuoglu, Nando de Freitas", "bibtex": null, "read": true, "note_id": 89, "deleted_at": null, "last_modified_at": "2021-03-29T16:15:07.352650+00:00", "last_accessed_at": null, "tag_names": []}, "34": {"id": 34, "user_id": 1, "url": "https://arxiv.org/pdf/1602.07714.pdf", "title": "Learning values across many orders of magnitude", "author": "Hado van Hasselt, Arthur Guez, Matteo Hessel, Volodymyr Mnih, David Silver", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-04-26T14:54:47.528611+00:00", "last_accessed_at": null, "tag_names": []}, "31": {"id": 31, "user_id": 1, "url": "https://arxiv.org/pdf/1707.06347.pdf", "title": "Proximal Policy Optimization Algorithms", "author": "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-04-27T14:12:33.473125+00:00", "last_accessed_at": null, "tag_names": ["deep-rl"]}, "30": {"id": 30, "user_id": 1, "url": "https://arxiv.org/pdf/1502.05477.pdf", "title": "Trust Region Policy Optimization", "author": "John Schulman, Sergey Levine, Philipp Moritz, Michael I. Jordan, Pieter Abbeel", "bibtex": null, "read": true, "note_id": null, "deleted_at": null, "last_modified_at": "2021-04-27T14:12:32.728932+00:00", "last_accessed_at": null, "tag_names": ["deep-rl"]}, "39": {"id": 39, "user_id": 1, "url": "https://arxiv.org/pdf/2105.08710.pdf", "title": "Fast and Slow Learning of Recurrent Independent Mechanisms", "author": "Kanika Madan, Nan Rosemary Ke, Anirudh Goyal, Bernhard Sch\u00f6lkopf, Yoshua Bengio", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-27T04:45:25.258314+00:00", "last_accessed_at": null, "tag_names": []}, "41": {"id": 41, "user_id": 1, "url": "https://arxiv.org/pdf/1602.05179.pdf", "title": "Equilibrium Propagation: Bridging the Gap Between Energy-Based Models and Backpropagation", "author": "Benjamin Scellier, Yoshua Bengio", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-27T04:47:21.549597+00:00", "last_accessed_at": null, "tag_names": []}, "43": {"id": 43, "user_id": 1, "url": "https://arxiv.org/pdf/2106.01655.pdf", "title": "Hierarchical Representation Learning for Markov Decision Processes", "author": "Lorenzo Steccanella, Simone Totaro, Anders Jonsson", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-06-08T12:25:32.892650+00:00", "last_accessed_at": null, "tag_names": []}, "40": {"id": 40, "user_id": 1, "url": "https://openreview.net/pdf/eed8bc189f0d1b75012a17b5872b04defb9f6e2a.pdf", "title": "Pretraining Reward-Free Representations for Data-Efficient Reinforcement Learning", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-27T04:46:22.477566+00:00", "last_accessed_at": null, "tag_names": []}, "36": {"id": 36, "user_id": 1, "url": "https://openreview.net/pdf?id=QFYnKlBJYR", "title": "REINFORCEMENT LEARNING  WITH RANDOM DELAYS", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-02T15:11:51.578136+00:00", "last_accessed_at": null, "tag_names": []}, "35": {"id": 35, "user_id": 1, "url": "https://arxiv.org/pdf/1511.06295.pdf", "title": "Policy Distillation", "author": "Andrei A. Rusu, Sergio Gomez Colmenarejo, Caglar Gulcehre, Guillaume Desjardins, James Kirkpatrick, Razvan Pascanu, Volodymyr Mnih, Koray Kavukcuoglu, Raia Hadsell", "bibtex": null, "read": true, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-12T02:31:41.237966+00:00", "last_accessed_at": null, "tag_names": ["deep-rl"]}, "38": {"id": 38, "user_id": 1, "url": "https://papers.nips.cc/paper/2018/file/6d0f846348a856321729a2f36734d1a7-Paper.pdf", "title": "Entropy and mutual information in models of deep neural networks", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-27T04:42:56.108754+00:00", "last_accessed_at": null, "tag_names": []}, "42": {"id": 42, "user_id": 1, "url": "https://arxiv.org/pdf/2105.13231.pdf", "title": "AndroidEnv: A Reinforcement Learning Platform for Android", "author": "Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici, Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad, Doina Precup", "bibtex": null, "read": true, "note_id": null, "deleted_at": null, "last_modified_at": "2021-05-31T21:40:50.864694+00:00", "last_accessed_at": null, "tag_names": []}, "37": {"id": 37, "user_id": 1, "url": "https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf", "title": "Human Level Control Through Deep Reinforcement Learning", "author": null, "bibtex": "T", "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-06-21T19:45:15.015194+00:00", "last_accessed_at": null, "tag_names": ["deep-rl"]}, "45": {"id": 45, "user_id": 1, "url": "https://hhixl.net/media/32/shannon1948.pdf", "title": "A Mathematical Theory of Communication", "author": "CLAUDE E. SHANNON", "bibtex": null, "read": null, "note_id": 178, "deleted_at": null, "last_modified_at": "2021-07-11T22:49:38.821937+00:00", "last_accessed_at": null, "tag_names": ["math"]}, "49": {"id": 49, "user_id": 1, "url": "https://arxiv.org/pdf/2107.06217.pdf", "title": "What classifiers know what they don't?", "author": "Mohamed Ishmael Belghazi, David Lopez-Paz", "bibtex": null, "read": true, "note_id": null, "deleted_at": null, "last_modified_at": "2021-07-14T20:25:40.737617+00:00", "last_accessed_at": null, "tag_names": ["uncertainty"]}, "27": {"id": 27, "user_id": 1, "url": "https://raw.githubusercontent.com/rltheorybook/rltheorybook.github.io/6644fc5f99bbcd6ddb2d8c6ff7e871704340cd0f/rltheorybook_AJKS.pdf", "title": "Reinforcement Learning: Theory and Algorithms", "author": "Alekh Agarwal, Nan Jiang, Sham M. Kakade, Wen Sun", "bibtex": null, "read": null, "note_id": 99, "deleted_at": null, "last_modified_at": "2021-06-07T23:26:06.730995+00:00", "last_accessed_at": null, "tag_names": ["rl-theory"]}, "44": {"id": 44, "user_id": 1, "url": "https://arxiv.org/pdf/2102.09808.pdf", "title": "Training cascaded networks for speeded decisions using a temporal-difference loss", "author": "Michael L. Iuzzolino, Michael C. Mozer, Samy Bengio", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-06-08T15:30:10.141790+00:00", "last_accessed_at": null, "tag_names": []}, "53": {"id": 53, "user_id": 1, "url": "https://bsi-ni.brain.riken.jp/database/file/176/181.pdf", "title": "Natural Gradient Works Efficiently in Learning", "author": null, "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-07-29T19:57:43.916805+00:00", "last_accessed_at": null, "tag_names": []}, "47": {"id": 47, "user_id": 1, "url": "https://www2.math.upenn.edu/~wilf/gfologyLinked2.pdf", "title": "generatingfunctionology", "author": "Herbert S. Wilf", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-07-15T21:11:24.815890+00:00", "last_accessed_at": null, "tag_names": ["math"]}, "50": {"id": 50, "user_id": 1, "url": "https://arxiv.org/pdf/2103.03206.pdf", "title": "Perceiver: General Perception with Iterative Attention", "author": "Andrew Jaegle, Felix Gimeno, Andrew Brock, Andrew Zisserman, Oriol Vinyals, Joao Carreira", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-07-18T17:02:09.808708+00:00", "last_accessed_at": null, "tag_names": []}, "54": {"id": 54, "user_id": 1, "url": "https://arxiv.org/pdf/2107.05407.pdf", "title": "PonderNet: Learning to Ponder", "author": "Andrea Banino, Jan Balaguer, Charles Blundell", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-08-19T03:02:16.433605+00:00", "last_accessed_at": null, "tag_names": []}, "48": {"id": 48, "user_id": 1, "url": "https://arxiv.org/pdf/1812.02648.pdf", "title": "Deep Reinforcement Learning and the Deadly Triad", "author": "Hado van Hasselt, Yotam Doron, Florian Strub, Matteo Hessel, Nicolas Sonnerat, Joseph Modayil", "bibtex": null, "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-06-29T21:43:57.203975+00:00", "last_accessed_at": null, "tag_names": ["deep-rl"]}, "46": {"id": 46, "user_id": 1, "url": "http://proceedings.mlr.press/v89/czarnecki19a/czarnecki19a.pdf", "title": "Distilling Policy Distillation", "author": "Wojciech M. Czarnecki, Razvan Pascanu, Simon Osindero, Siddhant Jayakumar, Grzegorz Swirszcz, Max Jaderberg", "bibtex": "@InProceedings{pmlr-v89-czarnecki19a,\n  title = \t {Distilling Policy Distillation},\n  author =       {Czarnecki, Wojciech M. and Pascanu, Razvan and Osindero, Simon and Jayakumar, Siddhant and Swirszcz, Grzegorz and Jaderberg, Max},\n  booktitle = \t {Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics},\n  pages = \t {1331--1340},\n  year = \t {2019},\n  editor = \t {Chaudhuri, Kamalika and Sugiyama, Masashi},\n  volume = \t {89},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {16--18 Apr},\n  publisher =    {PMLR},\n  pdf = \t {http://proceedings.mlr.press/v89/czarnecki19a/czarnecki19a.pdf},\n  url = \t {http://proceedings.mlr.press/v89/czarnecki19a.html},\n  abstract = \t {The transfer of knowledge from one policy to another is an important tool in Deep Reinforcement Learning. This process, referred to as distillation, has been used to great success, for example, by enhancing the optimisation of agents, leading to stronger performance faster, on harder domains. Despite the widespread use and conceptual simplicity of distillation, many different formulations are used in practice, and the subtle variations between them can often drastically change the performance and the resulting objective that is being optimised. In this work, we rigorously explore the entire landscape of policy distillation, comparing the motivations and strengths of each variant through theoretical and empirical analysis. Our results point to three distillation techniques, that are preferred depending on specifics of the task. Specifically a newly proposed expected entropy regularised distillation allows for quicker learning in a wide range of situations, while still guaranteeing convergence.}\n}", "read": null, "note_id": null, "deleted_at": null, "last_modified_at": "2021-06-22T18:57:40.359436+00:00", "last_accessed_at": null, "tag_names": []}};

# Table

## Empty
<Canvas>
  <Story name='Empty'>
    <div className='background-light'>
      <Table
        data={{}}
        selectable={true}
        cols={[
          {
            heading: 'Title',
            className: '',
            render: x => x['title'],
          },{
            heading: 'Last Modified',
            className: '',
            render: x => toRelativeDateString(new Date(x.last_modified_at)),
          },
        ]}
      />
    </div>
  </Story>
</Canvas>

## Document Table
<Canvas>
  <Story name='DocumentTable'>
    <div className='background-light'>
      <DocumentTable entities={entities} selectable={true} />
    </div>
  </Story>
</Canvas>

## Table 2
<Canvas>
  <Story name='Table2'>
    <div className='background-light'>
      <Table
        data={entities}
        selectable={true}
        cols={[
          {
            heading: 'Title',
            className: '',
            render: x => x['title'],
          },{
            heading: 'Last Modified',
            className: '',
            render: x => toRelativeDateString(new Date(x.last_modified_at)),
          },
        ]}
      />
    </div>
  </Story>
</Canvas>
